{"cells":[{"metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## # Introduction\n<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"},{"metadata":{"dc":{"key":"3"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom collections import Counter\nimport re\n\n# Download stopwords \nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n# Fetch the text from Project Gutenberg \nurl = \"https://www.gutenberg.org/files/16/16-h/16-h.htm\"  \nresponse = requests.get(url)\n\n# Parse the HTML using BeautifulSoup\nsoup = BeautifulSoup(response.content, \"html.parser\")\ntext = soup.get_text()\n\n# Clean the text: remove punctuation, normalize to lowercase, and split into words\ncleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)  \ncleaned_text = cleaned_text.lower()  \nwords = cleaned_text.split()  \n\n# Remove stopwords\nstop_words = set(stopwords.words(\"english\"))\nmeaningful_words = [word for word in words if word not in stop_words]\n\n# Count word frequencies\nword_counts = Counter(meaningful_words)\n\n# Get the 10 most common meaningful words\nmost_common_words = word_counts.most_common(10)\nprint(\"Top 10 most common meaningful words:\", most_common_words)\n\n# Define character names (normalize to lowercase for comparison)\ncharacter_names = [\"peter\", \"wendy\", \"hook\", \"tinker\", \"bell\", \"darling\", \"neverland\", \"john\", \"michael\"]\n\n# Check which of the most common words are character names\nprotagonists = [word for word, count in most_common_words if word in character_names]\n\n# Save the answer\nprint(\"Protagonists among the top 10:\", protagonists)\n","execution_count":6,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nTop 10 most common meaningful words: [('peter', 382), ('said', 358), ('wendy', 333), ('would', 217), ('one', 211), ('hook', 153), ('could', 142), ('cried', 136), ('john', 127), ('time', 122)]\nProtagonists among the top 10: ['peter', 'wendy', 'hook', 'john']\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}